{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2NwQQQ1aIJ5",
        "tags": []
      },
      "source": [
        "# Using Image Embeddings\n",
        "\n",
        "FiftyOne provides a powerful [embeddings visualization](https://voxel51.com/docs/fiftyone/user_guide/brain.html#visualizing-embeddings) capability that you can use to generate low-dimensional representations of the samples and objects in your datasets.\n",
        "\n",
        "This notebook highlights several applications of visualizing image embeddings, with the goal of motivating some of the many possible workflows that you can perform.\n",
        "\n",
        "Specifically, we'll cover the following concepts:\n",
        "\n",
        "- Loading datasets from the [FiftyOne Dataset Zoo](https://voxel51.com/docs/fiftyone/user_guide/dataset_zoo_datasets.html)\n",
        "- Using [compute_visualization()](https://voxel51.com/docs/fiftyone/api/fiftyone.brain.html#fiftyone.brain.compute_visualization) to generate 2D representations of images\n",
        "- Providing custom embeddings to [compute_visualization()](https://voxel51.com/docs/fiftyone/api/fiftyone.brain.html#fiftyone.brain.compute_visualization)\n",
        "- Visualizing embeddings via [interactive plots](https://voxel51.com/docs/fiftyone/user_guide/plots.html) connected to the [FiftyOne App](https://voxel51.com/docs/fiftyone/user_guide/app.html)\n",
        "\n",
        "And we'll demonstrate how to use embeddings to:\n",
        "\n",
        "- Identify anomolous/incorrect image labels\n",
        "- Find examples of scenarios of interest\n",
        "- Pre-annotate unlabeled data for training\n",
        "\n",
        "**So, what's the takeaway?**\n",
        "\n",
        "Combing through individual images in a dataset and staring at aggregate performance metrics trying to figure out how to improve the performance of a model is an ineffective and time-consuming process. Visualizing your dataset in a low-dimensional embedding space is a powerful workflow that can reveal patterns and clusters in your data that can answer important questions about the critical failure modes of your model and how to augment your dataset to address these failures.\n",
        "\n",
        "Using the FiftyOne Brain's [embeddings visualization](https://voxel51.com/docs/fiftyone/user_guide/brain.html#visualizing-embeddings) capability on your ML projects can help you uncover hidden patterns in your data and take action to improve the quality of your datasets and models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zC91-QZv9T27"
      },
      "source": [
        "![embeddings-sizzle](https://github.com/voxel51/fiftyone/blob/v1.0.2/docs/source/tutorials/images/image_embeddings_zero_cluster.gif?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJgEqAq_NrkI"
      },
      "source": [
        "## Setup\n",
        "\n",
        "If you haven’t already, install FiftyOne:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFZrLwS99T29",
        "outputId": "0a94256b-b65c-4fc7-88cb-5e92121ee0f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fiftyone\n",
            "  Downloading fiftyone-1.0.2-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting aiofiles (from fiftyone)\n",
            "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting argcomplete (from fiftyone)\n",
            "  Downloading argcomplete-3.5.1-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from fiftyone) (4.12.3)\n",
            "Collecting boto3 (from fiftyone)\n",
            "  Downloading boto3-1.35.66-py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from fiftyone) (5.5.0)\n",
            "Collecting dacite<1.8.0,>=1.6.0 (from fiftyone)\n",
            "  Downloading dacite-1.7.0-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: Deprecated in /usr/local/lib/python3.10/dist-packages (from fiftyone) (1.2.15)\n",
            "Collecting ftfy (from fiftyone)\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.10/dist-packages (from fiftyone) (4.11.0)\n",
            "Collecting hypercorn>=0.13.2 (from fiftyone)\n",
            "  Downloading hypercorn-0.17.3-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: Jinja2>=3 in /usr/local/lib/python3.10/dist-packages (from fiftyone) (3.1.4)\n",
            "Collecting kaleido!=0.2.1.post1 (from fiftyone)\n",
            "  Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl.metadata (15 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from fiftyone) (3.8.0)\n",
            "Collecting mongoengine==0.24.2 (from fiftyone)\n",
            "  Downloading mongoengine-0.24.2-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting motor>=2.5 (from fiftyone)\n",
            "  Downloading motor-3.6.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fiftyone) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from fiftyone) (24.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from fiftyone) (2.2.2)\n",
            "Requirement already satisfied: Pillow>=6.2 in /usr/local/lib/python3.10/dist-packages (from fiftyone) (11.0.0)\n",
            "Requirement already satisfied: plotly>=4.14 in /usr/local/lib/python3.10/dist-packages (from fiftyone) (5.24.1)\n",
            "Collecting pprintpp (from fiftyone)\n",
            "  Downloading pprintpp-0.4.0-py2.py3-none-any.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from fiftyone) (5.9.5)\n",
            "Collecting pymongo<4.9,>=3.12 (from fiftyone)\n",
            "  Downloading pymongo-4.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from fiftyone) (2024.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from fiftyone) (6.0.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from fiftyone) (2024.9.11)\n",
            "Collecting retrying (from fiftyone)\n",
            "  Downloading retrying-1.3.4-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from fiftyone) (1.5.2)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from fiftyone) (0.24.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from fiftyone) (1.13.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from fiftyone) (75.1.0)\n",
            "Collecting sseclient-py<2,>=1.7.2 (from fiftyone)\n",
            "  Downloading sseclient_py-1.8.0-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting sse-starlette<1,>=0.10.3 (from fiftyone)\n",
            "  Downloading sse_starlette-0.10.3-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting starlette>=0.24.0 (from fiftyone)\n",
            "  Downloading starlette-0.41.3-py3-none-any.whl.metadata (6.0 kB)\n",
            "Collecting strawberry-graphql (from fiftyone)\n",
            "  Downloading strawberry_graphql-0.250.1-py3-none-any.whl.metadata (7.8 kB)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from fiftyone) (0.9.0)\n",
            "Collecting xmltodict (from fiftyone)\n",
            "  Downloading xmltodict-0.14.2-py2.py3-none-any.whl.metadata (8.0 kB)\n",
            "Collecting universal-analytics-python3<2,>=1.0.1 (from fiftyone)\n",
            "  Downloading universal_analytics_python3-1.1.1-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting pydash (from fiftyone)\n",
            "  Downloading pydash-8.0.4-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting fiftyone-brain<0.18,>=0.17.0 (from fiftyone)\n",
            "  Downloading fiftyone_brain-0.17.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting fiftyone-db<2.0,>=0.4 (from fiftyone)\n",
            "  Downloading fiftyone_db-1.1.7.tar.gz (7.9 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting voxel51-eta<0.14,>=0.13.0 (from fiftyone)\n",
            "  Downloading voxel51_eta-0.13.0-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from fiftyone) (4.10.0.84)\n",
            "Requirement already satisfied: exceptiongroup>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from hypercorn>=0.13.2->fiftyone) (1.2.2)\n",
            "Requirement already satisfied: h11 in /usr/local/lib/python3.10/dist-packages (from hypercorn>=0.13.2->fiftyone) (0.14.0)\n",
            "Collecting h2>=3.1.0 (from hypercorn>=0.13.2->fiftyone)\n",
            "  Downloading h2-4.1.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting priority (from hypercorn>=0.13.2->fiftyone)\n",
            "  Downloading priority-2.0.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting taskgroup (from hypercorn>=0.13.2->fiftyone)\n",
            "  Downloading taskgroup-0.0.0a4-py2.py3-none-any.whl.metadata (327 bytes)\n",
            "Requirement already satisfied: tomli in /usr/local/lib/python3.10/dist-packages (from hypercorn>=0.13.2->fiftyone) (2.1.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.10/dist-packages (from hypercorn>=0.13.2->fiftyone) (4.12.2)\n",
            "Collecting wsproto>=0.14.0 (from hypercorn>=0.13.2->fiftyone)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3->fiftyone) (3.0.2)\n",
            "INFO: pip is looking at multiple versions of motor to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting motor>=2.5 (from fiftyone)\n",
            "  Downloading motor-3.5.3-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=4.14->fiftyone) (9.0.0)\n",
            "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo<4.9,>=3.12->fiftyone)\n",
            "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette>=0.24.0->fiftyone) (3.7.1)\n",
            "Requirement already satisfied: httpx>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from universal-analytics-python3<2,>=1.0.1->fiftyone) (0.27.2)\n",
            "Collecting dill (from voxel51-eta<0.14,>=0.13.0->fiftyone)\n",
            "  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from voxel51-eta<0.14,>=0.13.0->fiftyone) (1.0.0)\n",
            "Requirement already satisfied: glob2 in /usr/local/lib/python3.10/dist-packages (from voxel51-eta<0.14,>=0.13.0->fiftyone) (0.7)\n",
            "Collecting jsonlines (from voxel51-eta<0.14,>=0.13.0->fiftyone)\n",
            "  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting py7zr (from voxel51-eta<0.14,>=0.13.0->fiftyone)\n",
            "  Downloading py7zr-0.22.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from voxel51-eta<0.14,>=0.13.0->fiftyone) (2.8.2)\n",
            "Collecting rarfile (from voxel51-eta<0.14,>=0.13.0->fiftyone)\n",
            "  Downloading rarfile-4.2-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from voxel51-eta<0.14,>=0.13.0->fiftyone) (2.32.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from voxel51-eta<0.14,>=0.13.0->fiftyone) (1.16.0)\n",
            "Collecting sortedcontainers (from voxel51-eta<0.14,>=0.13.0->fiftyone)\n",
            "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.10/dist-packages (from voxel51-eta<0.14,>=0.13.0->fiftyone) (5.2)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from voxel51-eta<0.14,>=0.13.0->fiftyone) (2.2.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->fiftyone) (2.6)\n",
            "Collecting botocore<1.36.0,>=1.35.66 (from boto3->fiftyone)\n",
            "  Downloading botocore-1.35.66-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3->fiftyone)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3->fiftyone)\n",
            "  Downloading s3transfer-0.10.4-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from Deprecated->fiftyone) (1.16.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from ftfy->fiftyone) (0.2.13)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fiftyone) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fiftyone) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fiftyone) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fiftyone) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fiftyone) (3.2.0)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->fiftyone) (2024.2)\n",
            "Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.10/dist-packages (from scikit-image->fiftyone) (3.4.2)\n",
            "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image->fiftyone) (2.36.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image->fiftyone) (2024.9.20)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image->fiftyone) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->fiftyone) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->fiftyone) (3.5.0)\n",
            "Collecting graphql-core<3.4.0,>=3.2.0 (from strawberry-graphql->fiftyone)\n",
            "  Downloading graphql_core-3.2.5-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette>=0.24.0->fiftyone) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette>=0.24.0->fiftyone) (1.3.1)\n",
            "Collecting hyperframe<7,>=6.0 (from h2>=3.1.0->hypercorn>=0.13.2->fiftyone)\n",
            "  Downloading hyperframe-6.0.1-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting hpack<5,>=4.0 (from h2>=3.1.0->hypercorn>=0.13.2->fiftyone)\n",
            "  Downloading hpack-4.0.0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.10.0->universal-analytics-python3<2,>=1.0.1->fiftyone) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.10.0->universal-analytics-python3<2,>=1.0.1->fiftyone) (1.0.7)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonlines->voxel51-eta<0.14,>=0.13.0->fiftyone) (24.2.0)\n",
            "Collecting texttable (from py7zr->voxel51-eta<0.14,>=0.13.0->fiftyone)\n",
            "  Downloading texttable-1.7.0-py2.py3-none-any.whl.metadata (9.8 kB)\n",
            "Collecting pycryptodomex>=3.16.0 (from py7zr->voxel51-eta<0.14,>=0.13.0->fiftyone)\n",
            "  Downloading pycryptodomex-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting pyzstd>=0.15.9 (from py7zr->voxel51-eta<0.14,>=0.13.0->fiftyone)\n",
            "  Downloading pyzstd-0.16.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.4 kB)\n",
            "Collecting pyppmd<1.2.0,>=1.1.0 (from py7zr->voxel51-eta<0.14,>=0.13.0->fiftyone)\n",
            "  Downloading pyppmd-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.7 kB)\n",
            "Collecting pybcj<1.1.0,>=1.0.0 (from py7zr->voxel51-eta<0.14,>=0.13.0->fiftyone)\n",
            "  Downloading pybcj-1.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Collecting multivolumefile>=0.2.3 (from py7zr->voxel51-eta<0.14,>=0.13.0->fiftyone)\n",
            "  Downloading multivolumefile-0.2.3-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting inflate64<1.1.0,>=1.0.0 (from py7zr->voxel51-eta<0.14,>=0.13.0->fiftyone)\n",
            "  Downloading inflate64-1.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Collecting brotli>=1.1.0 (from py7zr->voxel51-eta<0.14,>=0.13.0->fiftyone)\n",
            "  Downloading Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->voxel51-eta<0.14,>=0.13.0->fiftyone) (3.4.0)\n",
            "Downloading fiftyone-1.0.2-py3-none-any.whl (10.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mongoengine-0.24.2-py3-none-any.whl (108 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.9/108.9 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dacite-1.7.0-py3-none-any.whl (12 kB)\n",
            "Downloading fiftyone_brain-0.17.0-py3-none-any.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.1/98.1 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hypercorn-0.17.3-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.7/61.7 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl (79.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.9/79.9 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading motor-3.5.3-py3-none-any.whl (74 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.7/74.7 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pymongo-4.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sse_starlette-0.10.3-py3-none-any.whl (8.0 kB)\n",
            "Downloading sseclient_py-1.8.0-py2.py3-none-any.whl (8.8 kB)\n",
            "Downloading starlette-0.41.3-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading universal_analytics_python3-1.1.1-py3-none-any.whl (10 kB)\n",
            "Downloading voxel51_eta-0.13.0-py2.py3-none-any.whl (943 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m943.1/943.1 kB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Downloading argcomplete-3.5.1-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading boto3-1.35.66-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pprintpp-0.4.0-py2.py3-none-any.whl (16 kB)\n",
            "Downloading pydash-8.0.4-py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.9/101.9 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading retrying-1.3.4-py3-none-any.whl (11 kB)\n",
            "Downloading strawberry_graphql-0.250.1-py3-none-any.whl (295 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.2/295.2 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xmltodict-0.14.2-py2.py3-none-any.whl (10.0 kB)\n",
            "Downloading botocore-1.35.66-py3-none-any.whl (12.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m96.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_core-3.2.5-py3-none-any.whl (203 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.2/203.2 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h2-4.1.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading s3transfer-0.10.4-py3-none-any.whl (83 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.2/83.2 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Downloading dill-0.3.9-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.4/119.4 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
            "Downloading priority-2.0.0-py3-none-any.whl (8.9 kB)\n",
            "Downloading py7zr-0.22.0-py3-none-any.whl (67 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.9/67.9 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rarfile-4.2-py3-none-any.whl (29 kB)\n",
            "Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
            "Downloading taskgroup-0.0.0a4-py2.py3-none-any.whl (9.1 kB)\n",
            "Downloading Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m79.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hpack-4.0.0-py3-none-any.whl (32 kB)\n",
            "Downloading hyperframe-6.0.1-py3-none-any.whl (12 kB)\n",
            "Downloading inflate64-1.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (93 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multivolumefile-0.2.3-py3-none-any.whl (17 kB)\n",
            "Downloading pybcj-1.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycryptodomex-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m79.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyppmd-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.9/138.9 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyzstd-0.16.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (413 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m413.7/413.7 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading texttable-1.7.0-py2.py3-none-any.whl (10 kB)\n",
            "Building wheels for collected packages: fiftyone-db\n",
            "  Building wheel for fiftyone-db (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fiftyone-db: filename=fiftyone_db-1.1.7-py3-none-manylinux1_x86_64.whl size=42156157 sha256=b70bfc7b5fae2ff091ef859c7260ccf73a1f0c3377d76ed96478d26d5ee6e7ab\n",
            "  Stored in directory: /root/.cache/pip/wheels/ce/8b/e8/4f778229cacacc9c4e9871a9e0d7bce98fc99b8c01af0ea669\n",
            "Successfully built fiftyone-db\n",
            "Installing collected packages: texttable, sseclient-py, sortedcontainers, pprintpp, kaleido, brotli, xmltodict, wsproto, taskgroup, retrying, rarfile, pyzstd, pyppmd, pydash, pycryptodomex, pybcj, priority, multivolumefile, jsonlines, jmespath, inflate64, hyperframe, hpack, graphql-core, ftfy, fiftyone-db, dnspython, dill, dacite, argcomplete, aiofiles, strawberry-graphql, starlette, pymongo, py7zr, h2, botocore, voxel51-eta, universal-analytics-python3, sse-starlette, s3transfer, motor, mongoengine, hypercorn, fiftyone-brain, boto3, fiftyone\n",
            "Successfully installed aiofiles-24.1.0 argcomplete-3.5.1 boto3-1.35.66 botocore-1.35.66 brotli-1.1.0 dacite-1.7.0 dill-0.3.9 dnspython-2.7.0 fiftyone-1.0.2 fiftyone-brain-0.17.0 fiftyone-db-1.1.7 ftfy-6.3.1 graphql-core-3.2.5 h2-4.1.0 hpack-4.0.0 hypercorn-0.17.3 hyperframe-6.0.1 inflate64-1.0.0 jmespath-1.0.1 jsonlines-4.0.0 kaleido-0.2.1 mongoengine-0.24.2 motor-3.5.3 multivolumefile-0.2.3 pprintpp-0.4.0 priority-2.0.0 py7zr-0.22.0 pybcj-1.0.2 pycryptodomex-3.21.0 pydash-8.0.4 pymongo-4.8.0 pyppmd-1.1.0 pyzstd-0.16.2 rarfile-4.2 retrying-1.3.4 s3transfer-0.10.4 sortedcontainers-2.4.0 sse-starlette-0.10.3 sseclient-py-1.8.0 starlette-0.41.3 strawberry-graphql-0.250.1 taskgroup-0.0.0a4 texttable-1.7.0 universal-analytics-python3-1.1.1 voxel51-eta-0.13.0 wsproto-1.2.0 xmltodict-0.14.2\n"
          ]
        }
      ],
      "source": [
        "!pip install fiftyone"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mz8LE-289T2-"
      },
      "source": [
        "In this tutorial, we'll use some PyTorch models to generate embeddings, and we'll use the (default) [UMAP method](https://github.com/lmcinnes/umap) to generate embeddings, so we'll need to install the corresponding packages:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kob347uK5ET",
        "outputId": "50d595bd-7225-4668-d6e5-0c7358479047"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
            "Collecting umap-learn\n",
            "  Downloading umap_learn-0.5.7-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n",
            "Requirement already satisfied: scipy>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (1.5.2)\n",
            "Requirement already satisfied: numba>=0.51.2 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (0.60.0)\n",
            "Collecting pynndescent>=0.5 (from umap-learn)\n",
            "  Downloading pynndescent-0.5.13-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from umap-learn) (4.66.6)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.2->umap-learn) (0.43.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from pynndescent>=0.5->umap-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22->umap-learn) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading umap_learn-0.5.7-py3-none-any.whl (88 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.8/88.8 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pynndescent-0.5.13-py3-none-any.whl (56 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pynndescent, umap-learn\n",
            "Successfully installed pynndescent-0.5.13 umap-learn-0.5.7\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision umap-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZJUGHhY9T2_"
      },
      "source": [
        "This tutorial will demonstrate the powerful [interactive plotting](https://voxel51.com/docs/fiftyone/user_guide/plots.html) capabilities of FiftyOne. In the FiftyOne App, you can bidirectionally interact with plots to identify interesting subsets of your data and take action on them!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzGW6D0-NwBH"
      },
      "source": [
        "## Part I: MNIST\n",
        "\n",
        "In this section, we'll be working with the [MNIST dataset](https://voxel51.com/docs/fiftyone/user_guide/dataset_zoo/datasets.html?highlight=mnist#dataset-zoo-mnist) from the FiftyOne Dataset Zoo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "GnzA9md8NF59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13fbca21-3376-4ad8-9c27-79a83676782c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100% |█████████████████| 566/566 [121.6ms elapsed, 0s remaining, 4.9K samples/s]  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:eta.core.utils: 100% |█████████████████| 566/566 [121.6ms elapsed, 0s remaining, 4.9K samples/s]  \n"
          ]
        }
      ],
      "source": [
        "import fiftyone as fo\n",
        "import fiftyone.zoo as foz\n",
        "\n",
        "dataset_dir = \"/content/drive/MyDrive/preprocessed-1stchali\"\n",
        "\n",
        "dataset_type = fo.types.ImageDirectory\n",
        "\n",
        "dataset = fo.Dataset.from_dir(\n",
        "    dataset_dir=dataset_dir,\n",
        "    dataset_type=dataset_type,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "TN0uua7_Fn_e",
        "outputId": "146f1627-689f-418a-cac4-11bdfa5ab990",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9a0x4rwM9T3B"
      },
      "source": [
        "To start, we'll just use the $10,000$ test images from the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "orgr7iUC9T3B"
      },
      "outputs": [],
      "source": [
        "# test_split = dataset.match_tags(\"test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xoj3j4az9T3B",
        "outputId": "4a67fb00-ac80-40aa-9287-5d2dc7d92550"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset:     mnist\n",
            "Media type:  image\n",
            "Num samples: 10000\n",
            "Sample fields:\n",
            "    id:               fiftyone.core.fields.ObjectIdField\n",
            "    filepath:         fiftyone.core.fields.StringField\n",
            "    tags:             fiftyone.core.fields.ListField(fiftyone.core.fields.StringField)\n",
            "    metadata:         fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.metadata.ImageMetadata)\n",
            "    created_at:       fiftyone.core.fields.DateTimeField\n",
            "    last_modified_at: fiftyone.core.fields.DateTimeField\n",
            "    ground_truth:     fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Classification)\n",
            "View stages:\n",
            "    1. MatchTags(tags=['test'], bool=True, all=False)\n"
          ]
        }
      ],
      "source": [
        "# print(test_split)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wscKfYCB9T3B"
      },
      "source": [
        "### Computing image embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsFBiBzb9T3C"
      },
      "source": [
        "Typically when generating low-dimensional representations of image datasets, one will use a deep model to generate embeddings for each image, say 1024 or 2028 dimensional, that are then passed to a dimensionality reduction method like [UMAP](https://github.com/lmcinnes/umap) or [t-SNE](https://lvdmaaten.github.io/tsne) to generate the 2D or 3D representation that is visualized.\n",
        "\n",
        "Such an intermediate embedding step is necessary when the images in the dataset have different sizes, or are too large for [UMAP](https://github.com/lmcinnes/umap) or [t-SNE](https://lvdmaaten.github.io/tsne) to directly process, or the dataset is too complex and a model trained to recognize the concepts of interest is required in order to produce interpretable embeddings.\n",
        "\n",
        "However, for a relatively small and fixed size dataset such as MNIST, we can pass the images themselves to the dimensionality reduction method.\n",
        "\n",
        "Let's use the [compute_visualization()](https://voxel51.com/docs/fiftyone/api/fiftyone.brain.html#fiftyone.brain.compute_visualization) method to generate our first representation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416,
          "referenced_widgets": [
            "4364af2cdc55469aaa9c374c345c64f4",
            "589353700f9e4a3f943a77650e9944aa",
            "deb27ffddb6c446ba3372e0dd4725f75",
            "f308542a31a546b6ac9b355b50f5063b",
            "644ce036a82c4da48f2e7394d263086c",
            "fdbb769ee36b457097a802d93b1c33ea",
            "14ef3835e087436f9a26338b0a6aeb2f",
            "f7f73d2f94b44486a9fcdedc3b7fc57e",
            "80f9c14dd5344f609b93b738078aa095",
            "38dca09d10424521b9db24e8cbb55054",
            "177004664d3c4331b75f902cb0d502e3"
          ]
        },
        "id": "KLxdncsm9T3C",
        "outputId": "aff13162-d24e-46a2-d8c6-b16389fea124"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating visualization...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.brain.visualization:Generating visualization...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "UMAP(n_jobs=1, random_state=51, verbose=True)\n",
            "Thu Nov 21 05:09:48 2024 Construct fuzzy simplicial set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Nov 21 05:09:49 2024 Finding Nearest Neighbors\n",
            "Thu Nov 21 05:09:53 2024 Finished Nearest Neighbor Search\n",
            "Thu Nov 21 05:09:53 2024 Construct embedding\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epochs completed:   0%|            0/500 [00:00]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4364af2cdc55469aaa9c374c345c64f4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tcompleted  0  /  500 epochs\n",
            "\tcompleted  50  /  500 epochs\n",
            "\tcompleted  100  /  500 epochs\n",
            "\tcompleted  150  /  500 epochs\n",
            "\tcompleted  200  /  500 epochs\n",
            "\tcompleted  250  /  500 epochs\n",
            "\tcompleted  300  /  500 epochs\n",
            "\tcompleted  350  /  500 epochs\n",
            "\tcompleted  400  /  500 epochs\n",
            "\tcompleted  450  /  500 epochs\n",
            "Thu Nov 21 05:09:54 2024 Finished embedding\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "import fiftyone.brain as fob\n",
        "\n",
        "# Construct a ``num_samples x num_pixels`` array of images\n",
        "embeddings = np.array([\n",
        "    cv2.imread(f, cv2.IMREAD_UNCHANGED).ravel()\n",
        "    for f in dataset.values(\"filepath\")\n",
        "])\n",
        "\n",
        "# Compute 2D representation\n",
        "results = fob.compute_visualization(\n",
        "    dataset,\n",
        "    embeddings=embeddings,\n",
        "    num_dims=2,\n",
        "    method=\"umap\",\n",
        "    brain_key=\"arecanut\",\n",
        "    verbose=True,\n",
        "    seed=51,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBKIP8Zq9T3C"
      },
      "source": [
        "The method returned a `results` object with a `points` attribute that contains a `10000 x 2` array of 2D embeddings for our samples that we'll visualize next."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cDTlRxG9T3C",
        "outputId": "e5e42fb7-af75-46af-d17a-11c09110c898"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'fiftyone.brain.visualization.VisualizationResults'>\n",
            "(10000, 2)\n"
          ]
        }
      ],
      "source": [
        "print(type(results))\n",
        "print(results.points.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iasd-hji9T3C"
      },
      "source": [
        "If you ever want to access this results object again from the dataset, you can do so with the dataset's `load_brain_results()` method, passing the `brain_key` that you used to store the results:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0oQ1e-M19T3D",
        "outputId": "a67be168-12f1-41b8-c558-4b5ba31dd036"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<fiftyone.brain.visualization.VisualizationResults at 0x7dbba3ddab00>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "dataset.load_brain_results(\"mnist_test\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEDP9SCf9T3D"
      },
      "source": [
        "### Visualization parameters\n",
        "\n",
        "There are two primary components to an embedding visualization: the method used to generate the embeddings, and the dimensionality reduction method used to compute a low-dimensional representation of the embeddings.\n",
        "\n",
        "The ``embeddings`` and ``model`` parameters of\n",
        "[compute_visualization()](https://voxel51.com/docs/fiftyone/api/fiftyone.brain.html#fiftyone.brain.compute_visualization) support a variety of ways to generate embeddings for your data:\n",
        "\n",
        "- Provide nothing, in which case a default general-purpose model is used to embed your data\n",
        "- Provide a [Model instance](https://voxel51.com/docs/fiftyone/api/fiftyone.core.models.html#fiftyone.core.models.Model) or the name of any model from the [FiftyOne Model Zoo](https://voxel51.com/docs/fiftyone/user_guide/model_zoo/index.html) that supports embeddings\n",
        "- Compute your own embeddings and provide them as an array\n",
        "- Specify the name of a field of your dataset in which embeddings are stored\n",
        "\n",
        "The ``method`` parameter of [compute_visualization()](https://voxel51.com/docs/fiftyone/api/fiftyone.brain.html#fiftyone.brain.compute_visualization) allows you to specify the dimensionality reduction method to use. The supported methods are:\n",
        "\n",
        "- `\"umap\"` **(default)**: Uniform Manifold Approximation and Projection ([UMAP](https://github.com/lmcinnes/umap))\n",
        "- `\"t-sne\"`: t-distributed Stochastic Neighbor Embedding ([t-SNE](https://lvdmaaten.github.io/tsne))\n",
        "- `\"pca\"`: Principal Component Analysis ([PCA](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zj9m5OFL9T3D"
      },
      "source": [
        "### Visualizing embeddings\n",
        "\n",
        "Now we're ready to use [results.visualize()](https://voxel51.com/docs/fiftyone/api/fiftyone.brain.visualization.html#fiftyone.brain.visualization.VisualizationResults.visualize) to visualize our representation.\n",
        "\n",
        "Although we could use this method in isolation, the real power of FiftyOne comes when you [attach plots to the FiftyOne App](https://voxel51.com/docs/fiftyone/user_guide/plots.html#attaching-plots), so that when points of interest are selected in the plot, the corresponding samples are automatically selected in the App, and vice versa.\n",
        "\n",
        "So, let's open the test split in the App:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "wMUO0Nd69T3E"
      },
      "outputs": [],
      "source": [
        "# Launch App instance\n",
        "session = fo.launch_app(test_split)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXXvAAO49T3E"
      },
      "source": [
        "![MNIST test split](https://github.com/voxel51/fiftyone/blob/v1.0.2/docs/source/tutorials/images/image_embeddings_test_split.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJ4EMkar9T3E"
      },
      "source": [
        "Now let's visualize the results in the [Embeddings Panel](https://docs.voxel51.com/user_guide/app.html#embeddings-panel) in the FiftyOne App, and color by ground truth label:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UcT0HXwB9T3E"
      },
      "source": [
        "![MNIST embeddings](https://github.com/voxel51/fiftyone/blob/v1.0.2/docs/source/tutorials/images/image_embeddings_panel.gif?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJGhNzkt9T3E"
      },
      "source": [
        "Notice that the scatterpoints are naturally clustered by color (ground truth label), which means that [UMAP](https://github.com/lmcinnes/umap) was able to capture the visual differences between the digits!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHfbRbU09T3E"
      },
      "source": [
        "### Scatterplot controls\n",
        "\n",
        "Now it's time to explore the scatterplot interactively. In the top of the panel, you will see controls that allow you to do the following:\n",
        "- The `Zoom`, `Pan`, `Zoom In`, `Zoom Out`, `Autoscale`, and `Reset axes` modes can be used to manipulate your current view\n",
        "- The `Box Select` and `Lasso Select` modes enable you to select points in the plot\n",
        "\n",
        "In `Box Select` or `Lasso Select` mode, drawing on the plot will select the points within the region you define. In addition, note that you can:\n",
        "- Hold shift to add a region to your selection\n",
        "- Double-click anywhere on the plot to deselect all points\n",
        "\n",
        "Since we chose a categorical label for the points, each ground truth label is given its own trace in the legend on the righthand side. You can interact with this legend to show/hide data:\n",
        "- Single-click on a trace to show/hide all points in that trace\n",
        "- Double-click on a trace to show/hide all *other* traces"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BV598y-O9T3F"
      },
      "source": [
        "### Exploring the embeddings\n",
        "\n",
        "Here's a couple suggestions for exploring the data:\n",
        "\n",
        "- Use `Lasso Select` to select the cluster of points corresponding to the `0` label. Note that the corresponding images loaded in the App are all images of zeros, as expected\n",
        "- Try selecting other clusters and viewing the images in the App\n",
        "- Click on the `0` label in the legend to hide the zeros. Now lasso the points from other traces that are in the `0` cluster. These are non-zero images in the dataset that are likley to be confused as zeros!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dc9tG5h49T3F"
      },
      "source": [
        "![likely zero confusions](https://github.com/voxel51/fiftyone/blob/v1.0.2/docs/source/tutorials/images/image_embeddings_zero_cluster.gif?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vans9tS9T3F"
      },
      "source": [
        "Now try double-clicking on the `0` legend entry so that only the `0` points are visible in the plot. Then use the `Lasso Select` to select the `0` points that are far away from the main `0` cluster. These are zero images in the dataset that are likely to be confused as non-zeroes by a model!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSyoanUF9T3F"
      },
      "source": [
        "![likely nonzero confusions](https://github.com/voxel51/fiftyone/blob/v1.0.2/docs/source/tutorials/images/image_embeddings_nonzero_cluster.gif?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUDiTnfw9T3F"
      },
      "source": [
        "Cool, right? It is clear that [compute_visualization()](https://voxel51.com/docs/fiftyone/api/fiftyone.brain.html#fiftyone.brain.compute_visualization) has picked up on some interesting structure in the test split of the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6FjFOv59T3F"
      },
      "source": [
        "### Pre-annotation of samples\n",
        "\n",
        "Now let's put the insights from the previous section to work.\n",
        "\n",
        "Imagine that you are [Yann LeCun](http://yann.lecun.com) or [Corinna Cortes](https://research.google/people/author121/), the creators of the MNIST dataset, and you have just invested the time to annotate the test split of the dataset by hand. Now, you have collected an additional 60K images of unlabeled digits that you want to use as a training split that you need to annotate.\n",
        "\n",
        "Let's see how [compute_visualization()](https://voxel51.com/docs/fiftyone/api/fiftyone.brain.html#fiftyone.brain.compute_visualization) can be used to efficiently pre-annotate the train split with minimal effort.\n",
        "\n",
        "First, let's regenerate embeddings for all 70,000 images in the combined test and train splits:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xU6qARnG9T3G",
        "outputId": "801be36b-41ec-4003-8fe8-dbce121587fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating visualization...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.brain.visualization:Generating visualization...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "UMAP(n_jobs=1, random_state=51, verbose=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Nov 21 04:51:17 2024 Construct fuzzy simplicial set\n",
            "Thu Nov 21 04:51:17 2024 Finding Nearest Neighbors\n",
            "Thu Nov 21 04:51:17 2024 Building RP forest with 18 trees\n",
            "Thu Nov 21 04:51:25 2024 NN descent for 16 iterations\n",
            "\t 1  /  16\n",
            "\t 2  /  16\n",
            "\t 3  /  16\n",
            "\t 4  /  16\n",
            "\tStopping threshold met -- exiting after 4 iterations\n",
            "Thu Nov 21 04:51:34 2024 Finished Nearest Neighbor Search\n",
            "Thu Nov 21 04:51:34 2024 Construct embedding\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-10-305bc9aac0b7>\", line 8, in <cell line: 8>\n",
            "    results = fob.compute_visualization(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/fiftyone/brain/__init__.py\", line 510, in compute_visualization\n",
            "    return fbv.compute_visualization(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/fiftyone/brain/visualization.py\", line 124, in compute_visualization\n",
            "    points = brain_method.fit(embeddings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/fiftyone/brain/visualization.py\", line 721, in fit\n",
            "    return _umap.fit_transform(embeddings)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/umap/umap_.py\", line 2928, in fit_transform\n",
            "    self.fit(X, y, force_all_finite, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/umap/umap_.py\", line 2817, in fit\n",
            "    self.embedding_, aux_data = self._fit_embed_data(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/umap/umap_.py\", line 2865, in _fit_embed_data\n",
            "    return simplicial_set_embedding(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/umap/umap_.py\", line 1109, in simplicial_set_embedding\n",
            "    embedding = spectral_layout(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/umap/spectral.py\", line 304, in spectral_layout\n",
            "    return _spectral_layout(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/umap/spectral.py\", line 519, in _spectral_layout\n",
            "    eigenvalues, eigenvectors = scipy.sparse.linalg.eigsh(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py\", line 1700, in eigsh\n",
            "    params.iterate()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py\", line 537, in iterate\n",
            "    self._arpack_solver(self.ido, self.bmat, self.which, self.k,\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n",
            "    module = getmodule(object, filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 878, in getmodule\n",
            "    os.path.realpath(f)] = module.__name__\n",
            "  File \"/usr/lib/python3.10/posixpath.py\", line 396, in realpath\n",
            "    path, ok = _joinrealpath(filename[:0], filename, strict, {})\n",
            "  File \"/usr/lib/python3.10/posixpath.py\", line 429, in _joinrealpath\n",
            "    newpath = join(path, name)\n",
            "  File \"/usr/lib/python3.10/posixpath.py\", line 82, in join\n",
            "    for b in map(os.fspath, p):\n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "object of type 'NoneType' has no len()",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-305bc9aac0b7>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Compute 2D representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m results = fob.compute_visualization(\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/fiftyone/brain/__init__.py\u001b[0m in \u001b[0;36mcompute_visualization\u001b[0;34m(samples, patches_field, embeddings, points, brain_key, num_dims, method, model, model_kwargs, force_square, alpha, batch_size, num_workers, skip_failures, progress, **kwargs)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m     return fbv.compute_visualization(\n\u001b[0m\u001b[1;32m    511\u001b[0m         \u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/fiftyone/brain/visualization.py\u001b[0m in \u001b[0;36mcompute_visualization\u001b[0;34m(samples, patches_field, embeddings, points, brain_key, num_dims, method, model, model_kwargs, force_square, alpha, batch_size, num_workers, skip_failures, progress, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Generating visualization...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0mpoints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbrain_method\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/fiftyone/brain/visualization.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, embeddings)\u001b[0m\n\u001b[1;32m    720\u001b[0m         )\n\u001b[0;32m--> 721\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_umap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/umap/umap_.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, force_all_finite, **kwargs)\u001b[0m\n\u001b[1;32m   2927\u001b[0m         \"\"\"\n\u001b[0;32m-> 2928\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2929\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"embedding\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/umap/umap_.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, force_all_finite, **kwargs)\u001b[0m\n\u001b[1;32m   2816\u001b[0m             )\n\u001b[0;32m-> 2817\u001b[0;31m             self.embedding_, aux_data = self._fit_embed_data(\n\u001b[0m\u001b[1;32m   2818\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raw_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/umap/umap_.py\u001b[0m in \u001b[0;36m_fit_embed_data\u001b[0;34m(self, X, n_epochs, init, random_state, **kwargs)\u001b[0m\n\u001b[1;32m   2864\u001b[0m         \"\"\"\n\u001b[0;32m-> 2865\u001b[0;31m         return simplicial_set_embedding(\n\u001b[0m\u001b[1;32m   2866\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/umap/umap_.py\u001b[0m in \u001b[0;36msimplicial_set_embedding\u001b[0;34m(data, graph, n_components, initial_alpha, a, b, gamma, negative_sample_rate, n_epochs, init, random_state, metric, metric_kwds, densmap, densmap_kwds, output_dens, output_metric, output_metric_kwds, euclidean_output, parallel, verbose, tqdm_kwds)\u001b[0m\n\u001b[1;32m   1108\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0minit\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"spectral\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1109\u001b[0;31m         embedding = spectral_layout(\n\u001b[0m\u001b[1;32m   1110\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/umap/spectral.py\u001b[0m in \u001b[0;36mspectral_layout\u001b[0;34m(data, graph, dim, random_state, metric, metric_kwds, tol, maxiter)\u001b[0m\n\u001b[1;32m    303\u001b[0m     \"\"\"\n\u001b[0;32m--> 304\u001b[0;31m     return _spectral_layout(\n\u001b[0m\u001b[1;32m    305\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/umap/spectral.py\u001b[0m in \u001b[0;36m_spectral_layout\u001b[0;34m(data, graph, dim, random_state, metric, metric_kwds, init, method, tol, maxiter)\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"eigsh\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m             eigenvalues, eigenvectors = scipy.sparse.linalg.eigsh(\n\u001b[0m\u001b[1;32m    520\u001b[0m                 \u001b[0mL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py\u001b[0m in \u001b[0;36meigsh\u001b[0;34m(A, k, M, sigma, which, v0, ncv, maxiter, tol, return_eigenvectors, Minv, OPinv, mode)\u001b[0m\n\u001b[1;32m   1699\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverged\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1700\u001b[0;31m             \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py\u001b[0m in \u001b[0;36miterate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    536\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mido\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mipntr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m             self._arpack_solver(self.ido, self.bmat, self.which, self.k,\n\u001b[0m\u001b[1;32m    538\u001b[0m                                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miparam\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2098\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2099\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2099\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2101\u001b[0;31m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[1;32m   2102\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[1;32m   2103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
          ]
        }
      ],
      "source": [
        "# Construct a ``num_samples x num_pixels`` array of images\n",
        "embeddings = np.array([\n",
        "    cv2.imread(f, cv2.IMREAD_UNCHANGED).ravel()\n",
        "    for f in dataset.values(\"filepath\")\n",
        "])\n",
        "\n",
        "# Compute 2D representation\n",
        "results = fob.compute_visualization(\n",
        "    dataset,\n",
        "    embeddings=embeddings,\n",
        "    num_dims=2,\n",
        "    method=\"umap\",\n",
        "    brain_key=\"mnist\",\n",
        "    verbose=True,\n",
        "    seed=51,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jp244abJ9T3G"
      },
      "source": [
        "Of course, our dataset already has ground truth labels for the train split, but let's pretend that's not the case and generate an array of `labels` for our visualization that colors the test split by its ground truth labels and marks all images in the train split as `unlabeled`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZRAzNteh9T3G"
      },
      "outputs": [],
      "source": [
        "from fiftyone import ViewField as F\n",
        "\n",
        "# Label `test` split samples by their ground truth label\n",
        "# Mark all samples in `train` split as `unlabeled`\n",
        "expr = F(\"$tags\").contains(\"test\").if_else(F(\"label\"), \"unlabeled\")\n",
        "labels = dataset.values(\"ground_truth\", expr=expr)\n",
        "# Set the `ground_truth.label` field to the computed labels\n",
        "dataset.set_values(\"ground_truth.label\", labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "bkrSwkWF9T3H"
      },
      "outputs": [],
      "source": [
        "# Launch a new App instance\n",
        "session = fo.launch_app(dataset, auto=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asn3TioR9T3H"
      },
      "source": [
        "![Unlabeled Images](https://github.com/voxel51/fiftyone/blob/v1.0.2/docs/source/tutorials/images/image_embeddings_unlabeled.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXrzWsOa9T3H"
      },
      "source": [
        "What's so great about this plot? Notice that the unlabeled points in our (to-be-labeled) train split are heavily clustered into the same clusters as the labeled points from the test split!\n",
        "\n",
        "Follow the simple workflow below to use FiftyOne's [in-App tagging feature](https://voxel51.com/docs/fiftyone/user_guide/app.html#tags-and-tagging) to efficiently assign proposed labels for all samples in the `train` split:\n",
        "1. Click on the `unlabeled` trace to hide it, and then use the predominant color of the labeled points in the cluster below to determine the identity of the cluster\n",
        "2. Now double-click on the `unlabeled` trace so that *only* the unlabeled points are visible in the plot\n",
        "3. Use the `Lasso Select` tool to select the `unlabeled` points in the cluster whose identity you just deduced\n",
        "4. Over in the App, click on the `tag` icon and assign a tag to the samples\n",
        "5. Repeat steps 1-4 for the other clusters\n",
        "\n",
        "Congratulations, you just pre-annotated ~60,000 training images!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEeqiPiJ9T3L"
      },
      "source": [
        "![pre-annotation](https://github.com/voxel51/fiftyone/blob/v1.0.2/docs/source/tutorials/images/image_embeddings_prelabel.gif?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ev-yiqs9T3L"
      },
      "source": [
        "You can easily print some statistics about the sample tags that you created:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T3SgR6i29T3L",
        "outputId": "d86905a0-ac75-45c9-fe28-9822865e8715"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'8': 5577, '6': 6006, '3': 6104, '7': 6361, '9': 6036, '5': 5389, 'train': 60000, '0': 5981, '4': 5737, '2': 5811, '1': 6937}\n"
          ]
        }
      ],
      "source": [
        "# The train split that we pre-annotated\n",
        "train_split = dataset.match_tags(\"train\")\n",
        "\n",
        "# Print state about labels that were added\n",
        "print(train_split.count_sample_tags())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADy2RYkH9T3L"
      },
      "source": [
        "The snippet below converts the sample tags into [Classification labels](https://voxel51.com/docs/fiftyone/user_guide/using_datasets.html#classification) in a new ``hypothesis`` field of the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QHkRu1bk9T3L",
        "outputId": "493408f0-71cf-4adf-f76d-c041fb0ab422"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 100% |█████████████| 60000/60000 [2.6m elapsed, 0s remaining, 353.0 samples/s]      \n",
            "{'0': 5981, '9': 6036, '8': 5572, '7': 6361, '6': 6006, '5': 5388, None: 69, '3': 6104, '1': 6937, '4': 5735, '2': 5811}\n"
          ]
        }
      ],
      "source": [
        "# Add a new Classification field called `hypothesis` to store our guesses\n",
        "with fo.ProgressBar() as pb:\n",
        "    for sample in pb(train_split):\n",
        "        labels = [t for t in sample.tags if t != \"train\"]\n",
        "        if labels:\n",
        "            sample[\"hypothesis\"] = fo.Classification(label=labels[0])\n",
        "            sample.save()\n",
        "\n",
        "# Print stats about the labels we created\n",
        "print(train_split.count_values(\"hypothesis.label\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OU3GH2O19T3L"
      },
      "source": [
        "In the example above, notice that 69 samples in the train split were not given a hypothesis (i.e., they were not included in the cluster-based tagging procedure). If you would like to retrieve them and manually assign tags, that is easy:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cSqFXeMl9T3L",
        "outputId": "3fe7e07a-1001-4877-a116-a7f0229b4936"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset:        mnist\n",
            "Media type:     image\n",
            "Num samples:    69\n",
            "Tags:           ['train']\n",
            "Sample fields:\n",
            "    filepath:     fiftyone.core.fields.StringField\n",
            "    tags:         fiftyone.core.fields.ListField(fiftyone.core.fields.StringField)\n",
            "    metadata:     fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.metadata.Metadata)\n",
            "    ground_truth: fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Classification)\n",
            "    hypothesis:   fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Classification)\n",
            "View stages:\n",
            "    1. MatchTags(tags=['train'])\n",
            "    2. Exists(field='hypothesis.label', bool=False)\n"
          ]
        }
      ],
      "source": [
        "no_hypothesis = train_split.exists(\"hypothesis.label\", False)\n",
        "print(no_hypothesis)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHFAVMHA9T3N"
      },
      "source": [
        "Depending on your application, you may be able to start training using the `hypothesis` labels directly by [exporting the dataset](https://voxel51.com/docs/fiftyone/user_guide/export_datasets.html) as, say, a classification directory tree structure:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NcCTtI3B9T3N"
      },
      "outputs": [],
      "source": [
        "# Export `hypothesis` labels as a classification directory tree format\n",
        "# `exists()` ensures that we only export samples with a hypothesis\n",
        "train_split.exists(\"hypothesis.label\").export(\n",
        "    export_dir=\"/path/for/dataset\",\n",
        "    dataset_type=fo.types.ImageClassificationDirectoryTree,\n",
        "    label_field=\"hypothesis\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POMqqOFW9T3N"
      },
      "source": [
        "Or perhaps you'll want to export the hypothesized labels to your annotation provider to fine-tune the labels for training.\n",
        "\n",
        "FiftyOne provides integrations for importing/exporting data to [Scale](https://voxel51.com/docs/fiftyone/api/fiftyone.utils.scale.html), [Labelbox](https://voxel51.com/docs/fiftyone/api/fiftyone.utils.labelbox.html), [Label Studio](https://docs.voxel51.com/integrations/labelstudio.html), [V7](https://docs.voxel51.com/integrations/v7.html), and [CVAT](https://voxel51.com/docs/fiftyone/user_guide/export_datasets.html#cvatimagedataset). Check out [this blog post](https://towardsdatascience.com/managing-annotation-mistakes-with-fiftyone-and-labelbox-fc6e87b51102) for more information about FiftyOne's Labelbox integration."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUZg8wPq9T3N"
      },
      "source": [
        "### Loading existing visualizations\n",
        "\n",
        "If you provide the `brain_key` argument to [compute_visualization()](https://voxel51.com/docs/fiftyone/api/fiftyone.brain.html#fiftyone.brain.compute_visualization), then the visualization results that you generate will be saved and you can recall them later.\n",
        "\n",
        "For example, we can recall the visualization results that we first computed on the test split:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gPBnBitF9T3O",
        "outputId": "15890bbe-4919-4170-ea64-0e33b5b4836b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['mnist', 'mnist_test']\n",
            "<class 'fiftyone.brain.visualization.VisualizationResults'>\n",
            "10000\n"
          ]
        }
      ],
      "source": [
        "# List brain runs saved on the dataset\n",
        "print(dataset.list_brain_runs())\n",
        "\n",
        "# Load the results for a brain run\n",
        "results = dataset.load_brain_results(\"mnist_test\")\n",
        "print(type(results))\n",
        "\n",
        "# Load the dataset view on which the results were computed\n",
        "results_view = dataset.load_brain_view(\"mnist_test\")\n",
        "print(len(results_view))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXLxResa9T3O"
      },
      "source": [
        "See [this docs page](https://voxel51.com/docs/fiftyone/user_guide/brain.html#managing-brain-runs) for more information about managing brain runs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6TgoMzY9T3O"
      },
      "source": [
        "## Part II: BDD100K\n",
        "\n",
        "In this section, we'll visualize embeddings from a deep model on the [BDD100K dataset](https://voxel51.com/docs/fiftyone/user_guide/dataset_zoo/datasets.html?highlight=bdd100k#dataset-zoo-bdd100k) from the FiftyOne Dataset Zoo and demonstrate some of the insights that you can glean from them.\n",
        "\n",
        "If you want to follow along youself, you will need to register at https://bdd-data.berkeley.edu in order to get links to download the data. See the [zoo docs](https://voxel51.com/docs/fiftyone/user_guide/dataset_zoo/datasets.html?highlight=bdd100k#dataset-zoo-bdd100k) for details on loading the dataset.\n",
        "\n",
        "We'll be working with the validation split, which contains 10,000 labeled images:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ii7udmD9T3O",
        "outputId": "ced2219e-d12f-49be-e5f9-2a988fecce32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Split 'validation' already prepared\n",
            "Loading existing dataset 'bdd100k-validation'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n"
          ]
        }
      ],
      "source": [
        "import fiftyone as fo\n",
        "import fiftyone.zoo as foz\n",
        "\n",
        "# The path to the source files that you manually downloaded\n",
        "source_dir = \"/path/to/dir-with-bdd100k-files\"\n",
        "\n",
        "dataset = foz.load_zoo_dataset(\"bdd100k\", split=\"validation\", source_dir=source_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-SnLEuzR9T3O"
      },
      "outputs": [],
      "source": [
        "session = fo.launch_app(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRBrd_XU9T3O"
      },
      "source": [
        "![BDD100K validation split](https://github.com/voxel51/fiftyone/blob/v1.0.2/docs/source/tutorials/images/image_embeddings_bdd100k.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_qtKDvp9T3P"
      },
      "source": [
        "### Computing image embeddings\n",
        "\n",
        "The BDD100K images are 1280 x 720 pixels, so we'll use a deep model to generate intermediate embeddings.\n",
        "\n",
        "Using a deep model not only enables us to visualize larger datasets or ones with different image sizes, it also enables us to key in on different features of the dataset, depending on the model that we use to generate embeddings. By default, [compute_visualization()](https://voxel51.com/docs/fiftyone/api/fiftyone.brain.html#fiftyone.brain.compute_visualization) will generate embeddings using a general-purpose model that works well for datasets of any kind.\n",
        "\n",
        "You can run the cell below to generate a 2D representation for the BDD100K validation split using FiftyOne's default model. You will likely want to run this on a machine with GPU, as this requires running inference on 10,000 images:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EmAgKRiz9T3P"
      },
      "outputs": [],
      "source": [
        "import fiftyone.brain as fob\n",
        "\n",
        "# Compute 2D representation\n",
        "# This will compute deep embeddings for all 10,000 images\n",
        "results = fob.compute_visualization(\n",
        "    dataset,\n",
        "    num_dims=2,\n",
        "    brain_key=\"img_viz\",\n",
        "    verbose=True,\n",
        "    seed=51,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fy27cSzl9T3P"
      },
      "source": [
        "Alternatively, you can provide your own custom embeddings via the `embeddings` parameter of [compute_visualization()](https://voxel51.com/docs/fiftyone/api/fiftyone.brain.html#fiftyone.brain.compute_visualization). The [FiftyOne Model Zoo](https://voxel51.com/docs/fiftyone/user_guide/model_zoo/index.html) provides dozens of models that expose embeddings that you can use for this purpose.\n",
        "\n",
        "For example, the cell below generates a visualization using pre-computed embeddings from a ResNet model from the zoo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O1tfsKYr9T3P"
      },
      "outputs": [],
      "source": [
        "# Load a resnet from the model zoo\n",
        "model = foz.load_zoo_model(\"resnet50-imagenet-torch\")\n",
        "\n",
        "# Verify that the model exposes embeddings\n",
        "print(model.has_embeddings)\n",
        "# True\n",
        "\n",
        "# Compute embeddings for each image\n",
        "embeddings = dataset.compute_embeddings(model)\n",
        "print(embeddings.shape)\n",
        "# 10000 x 2048\n",
        "\n",
        "# Compute 2D representation using pre-computed embeddings\n",
        "results = fob.compute_visualization(\n",
        "    dataset,\n",
        "    embeddings=embeddings,\n",
        "    num_dims=2,\n",
        "    brain_key=\"image_embeddings\",\n",
        "    verbose=True,\n",
        "    seed=51,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7xzj7Fa9T3P"
      },
      "source": [
        "Either way, we're ready to visualize our representation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VH7Y5FpX9T3P"
      },
      "source": [
        "### Visualizing embeddings\n",
        "\n",
        "As usual, we'll start by launching an App instance and opening the embeddings panel to interactively explore the results:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6oPe1nbp9T3Q"
      },
      "outputs": [],
      "source": [
        "session = fo.launch_app(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RCk4gFe9T3Q"
      },
      "source": [
        "The BDD100K dataset contains a handful of image-level labels, including scene type, time of day, and weather.\n",
        "\n",
        "Let's use the time of day labels to color our scatterplot:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVGc-Bu_9T3Q"
      },
      "source": [
        "![BDD100K embeddings](https://github.com/voxel51/fiftyone/blob/v1.0.2/docs/source/tutorials/images/image_embeddings_bdd100k_colorby.gif?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wE2jKYj29T3Q"
      },
      "source": [
        "Notice that the visualization has a dominant bimodal distribution corresponding to whether the time of day is `daytime` or `night`!\n",
        "\n",
        "You can investigate each cluster in more detail using the `Zoom` and `Pan` controls of the plot's modebar."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJa6dtEH9T3Q"
      },
      "source": [
        "### Investigating outliers\n",
        "\n",
        "Outlier clusters in these plots often correspond to images with distinctive properties. Let's `Lasso Select` some outlier regions to investigate:\n",
        "\n",
        "- The first cluster contains images where the dashboard of the vehicle heavily occludes the view\n",
        "- The second cluster contains images in rainy scenes where the windshield has water droplets on it\n",
        "- The third cluster contains images where a cell phone is in the field of view"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkyLAQrS9T3Q"
      },
      "source": [
        "![bdd100k-outliers](https://github.com/voxel51/fiftyone/blob/v1.0.2/docs/source/tutorials/images/image_embeddings_outliers.gif?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pr9DvtPV9T3Q"
      },
      "source": [
        "### Tagging label mistakes\n",
        "\n",
        "We can also use the scatterplot to tag samples whose `timeofday` labels are incorrect by taking the following actions:\n",
        "\n",
        "- Deselect all labels except `night` in the legend\n",
        "- Lasso select the nightime points (yellow) within the daytime cluster (red)\n",
        "- Click the tag icon in the upper-left corner of the sample grid in the App\n",
        "- Add an appropriate tag to the samples in the current view to mark the mistakes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jW7u_Gs59T3Q"
      },
      "source": [
        "![bdd100k-mistakes](https://github.com/voxel51/fiftyone/blob/v1.0.2/docs/source/tutorials/images/image_embeddings_tag_mistakes.gif?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iw3dAVB89T3Q"
      },
      "source": [
        "## Summary\n",
        "\n",
        "In this tutorial, we showed how to use FiftyOne to compute embeddings for image datasets and demonstrated a few of their many uses, including:\n",
        "\n",
        "- Visualizing the hidden structure of image datasets\n",
        "- Pre-annotating unlabeled data for training\n",
        "- Identifying anomolous/incorrect image labels\n",
        "- Finding examples of scenarios of interest\n",
        "\n",
        "**So, what's the takeaway?**\n",
        "\n",
        "Combing through individual images in a dataset and staring at aggregate performance metrics trying to figure out how to improve the performance of a model is an ineffective and time-consuming process.\n",
        "\n",
        "Visualizing your dataset in a low-dimensional embedding space is a powerful workflow that can reveal patterns and clusters in your data that can answer important questions about the critical failure modes of your model. It can also help you automate workflows like finding label mistakes and efficiently pre-annotating data.\n",
        "\n",
        "FiftyOne also supports visualizing embeddings for object detections. Stay tuned for an upcoming tutorial on the topic!"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "malaria-cell-images-analysis.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4364af2cdc55469aaa9c374c345c64f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_589353700f9e4a3f943a77650e9944aa",
              "IPY_MODEL_deb27ffddb6c446ba3372e0dd4725f75",
              "IPY_MODEL_f308542a31a546b6ac9b355b50f5063b"
            ],
            "layout": "IPY_MODEL_644ce036a82c4da48f2e7394d263086c"
          }
        },
        "589353700f9e4a3f943a77650e9944aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fdbb769ee36b457097a802d93b1c33ea",
            "placeholder": "​",
            "style": "IPY_MODEL_14ef3835e087436f9a26338b0a6aeb2f",
            "value": "Epochs completed: 100%| "
          }
        },
        "deb27ffddb6c446ba3372e0dd4725f75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7f73d2f94b44486a9fcdedc3b7fc57e",
            "max": 500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_80f9c14dd5344f609b93b738078aa095",
            "value": 500
          }
        },
        "f308542a31a546b6ac9b355b50f5063b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38dca09d10424521b9db24e8cbb55054",
            "placeholder": "​",
            "style": "IPY_MODEL_177004664d3c4331b75f902cb0d502e3",
            "value": " 500/500 [00:01]"
          }
        },
        "644ce036a82c4da48f2e7394d263086c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fdbb769ee36b457097a802d93b1c33ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14ef3835e087436f9a26338b0a6aeb2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f7f73d2f94b44486a9fcdedc3b7fc57e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80f9c14dd5344f609b93b738078aa095": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "38dca09d10424521b9db24e8cbb55054": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "177004664d3c4331b75f902cb0d502e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}